{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da79fa06",
   "metadata": {},
   "source": [
    "## Логистическая функция ошибки\n",
    "\n",
    "$$\n",
    "    logloss(a, y) = -y \\cdot \\log(a) - (1 - y) \\cdot \\log(1 - a)\n",
    "$$\n",
    "\n",
    "### Неприятное свойство логлосса\n",
    "Если мы выдаем для объекта 1-го класса оценку 0 или для объекта класса 0 оценку 1, то ошибка равна бесконечности. **То есть, грубая ошибка на одном объекте делает алгоритм бесполезным.**\n",
    "\n",
    "Для минимизации $logloss$ нужно уметь вычислять или оценивать вероятности принадлежности к классам.\n",
    "\n",
    "### Границы $logloss$\n",
    "\n",
    "$$\n",
    "    logloss(a, y) \\in \\left[0, -\\dfrac{q_1}{q}\\log(a) - \\dfrac{q_0}{q}\\log(1 - a)\\right]\n",
    "$$\n",
    "\n",
    "Верхняя граница -- это значение $logloss$ при константном алгоритме.\n",
    "\n",
    "### Связь с логистической регрессией\n",
    "\n",
    "$$\n",
    "    logloss(a, y) = -y \\cdot \\log(a) - (1 - y) \\cdot \\log(1 - a)\n",
    "$$\n",
    "$$\n",
    "    a = sigmoid(a, x) = \\dfrac{1}{1 + \\exp^{-w^{T}x}}\n",
    "$$\n",
    "$$\n",
    "    \\dfrac{\\partial logloss}{\\partial w} = (a - y) \\cdot x\n",
    "$$\n",
    "$$\n",
    "    w = w - \\alpha \\cdot (a - y) \\cdot x\n",
    "$$\n",
    "\n",
    "### Связь с расхождением Кульбакка-Лейблера\n",
    "\n",
    "Расхождение Кульбака-Лейблера ($KL, Kullback–Leibler divergence$) часто используют для вычисления непохожести двух распределений.\n",
    "\n",
    "#### Для непрерывных распредлений\n",
    "$$\n",
    "    D_{KL}(P || Q) = \\int p(z) \\cdot \\log\\dfrac{p(z)}{q(z)} dz\n",
    "$$\n",
    "\n",
    "#### Для дискретных распределений\n",
    "$$\n",
    "    D_{KL}(P || Q) = \\sum\\limits_{i}P_i \\cdot \\log\\dfrac{P_i}{Q_i}\n",
    "$$\n",
    "\n",
    "Теперь рассмотрим объект $x$ с меткой класса $y$. Истинное распределение -- $(1 - y, y)$, распределение нашего алгоритма -- $(1 - a, a)$. И посчитаем расхождение Кульбакка-Лейблера для такой ситуации:\n",
    "\n",
    "$$\n",
    "    D_{KL}(P || Q) = (1 - y) \\cdot \\log\\dfrac{1 - y}{1 - a} + y \\cdot \\log\\dfrac{y}{a} = -y \\cdot \\log a - (1 - y) \\cdot \\log(1 - a)\n",
    "$$\n",
    "Что полностью совпало с $logloss$.\n",
    "\n",
    "### Многоклассовый логлосс\n",
    "\n",
    "$$\n",
    "    logloss = -\\dfrac{1}{q}\\sum\\limits_{i = 1}^{q}\\sum\\limits_{j = 1}^{m}y_{ij} \\cdot \\log(a_{ij})\n",
    "$$\n",
    "\n",
    "$q$ - размер выборки, $l$ - число классов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
