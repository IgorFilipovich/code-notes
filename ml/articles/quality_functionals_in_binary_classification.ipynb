{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3f4980",
   "metadata": {},
   "source": [
    "## Функциналы качества в бинарной классификации\n",
    "\n",
    "### 1.  Accuracy\n",
    "\n",
    "Доля объектов, на которых алгоритм выдал правильные ответы.\n",
    "\n",
    "$$\n",
    "    Accuracy = \\dfrac{1}{m}\\sum\\limits_{i = 1}^{m}I[a_i = y_i]\n",
    "$$\n",
    "\n",
    "Явный недостаток: невалидна в случае дисбаланса классов, потому что с точки зрения точности выгодно почти всегда\n",
    "выдавать метку самого популярного класса.\n",
    "\n",
    "\n",
    "$$\n",
    "    Accuracy = \\dfrac{TP + TN}{TP + FP + TN + FN}\n",
    "$$\n",
    "\n",
    "### 2. Виды ошибок классификатора\n",
    "\n",
    "   * ошибка первого рода (Type 1 Error) --- объект ошибочно относится к положительному классу;\n",
    "   * ошибка второго рода (Type 2 Error) --- объект ошибочно относится к отрицательному классу.\n",
    "\n",
    "\n",
    "### 3. Recall (TPR, Sensitivity, Hit Rate)\n",
    "\n",
    "Показывает, какой процент объектов нами правильно классифицирован.\n",
    "\n",
    "$$\n",
    "    Recall = \\dfrac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### 4. Precision (Positive Predictive Value)\n",
    "\n",
    "Показывает, какой процент положительных объектов правильно классифицирован.\n",
    "\n",
    "$$\n",
    "    Precision = \\dfrac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "\n",
    "Точность и полнота --- \"ортогональные\" критерии качества. Легко построить алгоритм со 100%-й полнотой: он все объекты относит к классу 1, но при этом точность может быть очень низкой. Нетрудно построить алгоритм с близкой к 100% точностью: он относит к классу 1 только те объекты, в которых уверен, при этом полнота может быть низкая.\n",
    "\n",
    "\n",
    "### 5. $F_1$-мера\n",
    "\n",
    "Это просто среднее гармоническое Precision и Recall. Его максимизация приводит к максимизации и Precision, и Recall.\n",
    "\n",
    "$$\n",
    "    F_1 = \\dfrac{2}{\\dfrac{1}{Recall} + \\dfrac{1}{Precision}} = \\dfrac{2TP}{2TP + FP + FN}\n",
    "$$\n",
    "\n",
    "### 6. $F_\\beta$-мера\n",
    "\n",
    "$$\n",
    "    F_\\beta = \\dfrac{1}{\\dfrac{\\alpha}{Precision} + \\dfrac{1 - \\alpha}{Recall}} = \\dfrac{1}{\\alpha}\\dfrac{Precision \\cdot Recall}{Recall + \\left(\\dfrac{1}{\\alpha} - 1\\right) \\cdot Precision}\n",
    "$$,\n",
    "$$\n",
    "    \\beta^{2} = \\dfrac{1}{\\alpha} - 1 \\Rightarrow F_\\beta = (1 + \\beta^{2})\\dfrac{Precision \\cdot Recall}{Recall + \\beta^{2} \\cdot Precision}\n",
    "$$\n",
    "\n",
    "При использовании $F_\\beta$-меры линии уровня «перекашиваются», один из критериев (точность или полнота) становится важнее при\n",
    "оптимизации.\n",
    "\n",
    "### 7. Specificity (True Negative Rate)\n",
    "\n",
    "Показывает процент правильно классифицированных объектов негативного класса.\n",
    "\n",
    "$$\n",
    "    Specificity = TNR = \\dfrac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "### 8. False Positive Rate (fall-out, false alarm rate)\n",
    "\n",
    "Показывает долю объектов негативного класса, которые мы ошибочно отнесли к положительному.\n",
    "\n",
    "$$\n",
    "    FPR = \\dfrac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "### 9. Коэффициент Мэтьюса (MCC)\n",
    "\n",
    "Применяется на несбалансированных выборках. Лежит в отрезке [-1, 1].\n",
    "\n",
    "$$\n",
    "    MCC = \\dfrac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FN)(TN + FP)}}\n",
    "$$\n",
    "\n",
    "Давайте разберёмся, что означает эта «сложная формула». Рассмотрим среднее геометрическое точности и полноты:\n",
    "\n",
    "$$\n",
    "    \\sqrt{Precision \\cdot Recall} = \\dfrac{TP}{\\sqrt{(TP + FP)(TP + FN)}}\n",
    "$$\n",
    "\n",
    "Теперь возьмём среднее геометрическое точности и полноты класса 0 (т.е. считая это класс положительным), перемножив эти\n",
    "средние геометрические, получим:\n",
    "\n",
    "$$\n",
    "    \\sqrt{Precision \\cdot Recall \\cdot Precision_0 \\cdot Recall_0} = \\dfrac{TP \\cdot TN}{\\sqrt{(TP + FP)(TP + FN)(TN + FN)(TN + FP)}}\n",
    "$$\n",
    "\n",
    "### 10. Каппа Коэна (Cohen's Kappa)\n",
    "\n",
    "Его идея довольно простая: поскольку использование точности (Accuracy) вызывает сомнение в задачах с сильном дисбалансом классов, надо её значения немного перенормировать. Делается это с помощью статистики chance adjusted index: мы точность нашего решения (Accuracy) пронормируем с помощью точности, которую можно было получить случайно (Accuracychance). Под случайной здесь понимаем точность решения, которое получено из нашего случайной перестановкой ответов.\n",
    "\n",
    "### 11. Сбалансированная точность (Balanced Accuracy)\n",
    "\n",
    "$$\n",
    "    BA = \\dfrac{Recall + Recall_0}{2} = \\dfrac{1}{2}\\left(\\dfrac{TP}{TP + TN} + \\dfrac{TN}{TN + FP}\\right)\n",
    "$$\n",
    "\n",
    "Если в бинарной задаче классификации представителей двух классов примерно поровну, то TP + FN ≈ TN + FP ≈ m/2 и сбалансированная точность примерно равна точности обычной (Accuracy).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
